{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Setup Log Tables\n",
    "\n",
    "This notebook creates the required log tables for Bronze and Silver processing.\n",
    "\n",
    "**Important:** This notebook only needs to be run once. The `ensure_log_tables()` function is idempotent and safe to call multiple times.\n",
    "\n",
    "## Log Tables Created:\n",
    "\n",
    "1. **logs.bronze_processing_log** - Individual Bronze table processing records (partitioned by run_date, table_name)\n",
    "2. **logs.bronze_run_summary** - Bronze run aggregate statistics\n",
    "3. **logs.silver_processing_log** - Individual Silver CDC merge records (partitioned by run_date)\n",
    "4. **logs.silver_run_summary** - Silver run aggregate statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "log_to_console = True\n",
    "debug_mode = True  # Set to True for detailed logging during table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6g7",
   "metadata": {},
   "source": [
    "## Imports and Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module fabric.bootstrap\n",
    "# ---------------------\n",
    "# This cell enables a flexible module loading strategy:\n",
    "#\n",
    "# PRODUCTION (default): The `Files/code` directory is empty. This function does nothing,\n",
    "# and Python imports all modules from the stable, versioned Wheel in the Environment.\n",
    "#\n",
    "# DEVELOPMENT / HOTFIX: To bypass the 15-20 minute Fabric publish cycle for urgent fixes,\n",
    "# upload individual .py files to `Files/code` in the Lakehouse. This function prepends\n",
    "# that path to sys.path, so Python finds the override files first. All other modules\n",
    "# continue to load from the Wheel - only the uploaded files are replaced.\n",
    "#\n",
    "# Usage: Keep `Files/code` empty for production stability. Use it only for rapid\n",
    "# iteration during development or emergency hotfixes.\n",
    "\n",
    "from modules.fabric_bootstrap import ensure_module_path\n",
    "ensure_module_path()  # Now Python can find the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.logging_utils import configure_logging, ensure_log_tables\n",
    "from modules.spark_session import get_or_create_spark_session\n",
    "from modules.path_utils import detect_environment\n",
    "import logging\n",
    "\n",
    "# Configure file logging\n",
    "log_file = configure_logging(\n",
    "    run_name=\"setup_log_tables\",\n",
    "    enable_console_logging=log_to_console\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(f\"Logfile: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6g7h8i9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = get_or_create_spark_session(\n",
    "    app_name=\"Setup_Log_Tables\",\n",
    "    enable_hive=True\n",
    ")\n",
    "\n",
    "# Detect environment\n",
    "environment = detect_environment(spark)\n",
    "logger.info(f\"Detected environment: {environment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g7h8i9j0",
   "metadata": {},
   "source": [
    "## Create Log Tables\n",
    "\n",
    "The `ensure_log_tables()` function:\n",
    "- Checks if tables already exist\n",
    "- Creates them only if they don't exist\n",
    "- Is safe to run multiple times\n",
    "- Uses the correct partitioning strategy for each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h8i9j0k1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Starting log table initialization...\")\n",
    "    ensure_log_tables(spark, debug=debug_mode)\n",
    "    logger.info(\"✓ All log tables are ready!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUCCESS: Log tables setup completed\")\n",
    "    print(\"=\"*60)\n",
    "except Exception as e:\n",
    "    logger.error(f\"✗ Failed to setup log tables: {e}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ERROR: {e}\")\n",
    "    print(\"=\"*60)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Verify that all tables were successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0k1l2m3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify tables exist\n",
    "log_tables = [\n",
    "    \"logs.bronze_processing_log\",\n",
    "    \"logs.bronze_run_summary\",\n",
    "    \"logs.silver_processing_log\",\n",
    "    \"logs.silver_run_summary\"\n",
    "]\n",
    "\n",
    "print(\"\\nVerifying log tables:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "all_exist = True\n",
    "for table in log_tables:\n",
    "    exists = spark.catalog.tableExists(table)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {table}: {'EXISTS' if exists else 'NOT FOUND'}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n✓ All log tables verified successfully!\")\n",
    "    logger.info(\"All log tables verified successfully\")\n",
    "else:\n",
    "    print(\"\\n✗ Some log tables are missing!\")\n",
    "    logger.error(\"Some log tables are missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k1l2m3n4",
   "metadata": {},
   "source": [
    "## View Table Schemas (Optional)\n",
    "\n",
    "Display the schemas of the created tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l2m3n4o5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema for each table (optional)\n",
    "for table in log_tables:\n",
    "    if spark.catalog.tableExists(table):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Schema: {table}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        spark.table(table).printSchema()\n",
    "        \n",
    "        # Show table details\n",
    "        print(f\"\\nTable details:\")\n",
    "        spark.sql(f\"DESCRIBE EXTENDED {table}\").filter(\n",
    "            \"col_name IN ('Type', 'Provider', 'Location', 'Partition Provider')\"\n",
    "        ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "## Test Logging (Optional)\n",
    "\n",
    "Test if log functions work correctly by writing a test record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n4o5p6q7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test logging functions\n",
    "from modules.logging_utils import log_summary, log_batch\n",
    "from datetime import datetime, date\n",
    "\n",
    "test_enabled = False  # Set to True to run test\n",
    "\n",
    "if test_enabled:\n",
    "    logger.info(\"Running test log write...\")\n",
    "    \n",
    "    # Create test summary\n",
    "    test_run_ts = datetime.now().strftime(\"%Y%m%dT%H%M%S%f\")[:-3]\n",
    "    test_summary = {\n",
    "        \"run_ts\": test_run_ts,\n",
    "        \"run_date\": date.today(),\n",
    "        \"source\": \"test_setup\",\n",
    "        \"status\": \"SUCCESS\",\n",
    "        \"run_start\": datetime.now(),\n",
    "        \"run_end\": datetime.now(),\n",
    "        \"total_tables\": 1,\n",
    "        \"tables_success\": 1,\n",
    "        \"tables_empty\": 0,\n",
    "        \"tables_failed\": 0,\n",
    "        \"tables_skipped\": 0,\n",
    "        \"total_rows\": 0\n",
    "    }\n",
    "    \n",
    "    # Write test summary\n",
    "    run_log_id = log_summary(spark, test_summary, layer=\"bronze\")\n",
    "    logger.info(f\"Test summary written with log_id: {run_log_id}\")\n",
    "    \n",
    "    # Create test batch record\n",
    "    test_records = [{\n",
    "        \"run_ts\": test_run_ts,\n",
    "        \"run_date\": date.today(),\n",
    "        \"run_id\": f\"{test_run_ts}_test\",\n",
    "        \"source\": \"test_setup\",\n",
    "        \"table_name\": \"test_table\",\n",
    "        \"status\": \"SUCCESS\",\n",
    "        \"rows_processed\": 0,\n",
    "        \"start_time\": datetime.now(),\n",
    "        \"end_time\": datetime.now(),\n",
    "        \"duration_seconds\": 0,\n",
    "        \"load_mode\": \"snapshot\"\n",
    "    }]\n",
    "    \n",
    "    # Write test batch\n",
    "    log_batch(spark, test_records, layer=\"bronze\", run_log_id=run_log_id)\n",
    "    logger.info(\"Test batch written successfully\")\n",
    "    \n",
    "    print(\"\\n✓ Test logging completed successfully!\")\n",
    "    print(f\"  - Summary log_id: {run_log_id}\")\n",
    "    print(f\"  - Test records: {len(test_records)}\")\n",
    "else:\n",
    "    print(\"\\nTest logging skipped (set test_enabled=True to run test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o5p6q7r8",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Log tables are now created and ready to use.\n",
    "\n",
    "**Note:** From now on, all errors in `process_bronze_layer` and other notebooks will be automatically logged to these tables, even if an error occurs before the first log call."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
