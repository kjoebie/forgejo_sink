{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 20 — Silver CDC Merge Worker\n",
    "\n",
    "This notebook performs Change Data Capture (CDC) merge from Bronze to Silver layer.\n",
    "\n",
    "## CDC Architecture: Bronze History Pattern\n",
    "\n",
    "### How DELETE Detection Works\n",
    "\n",
    "Bronze incremental tables use **APPEND with run_ts partitioning**:\n",
    "```\n",
    "bronze.Dim_Relatie/\n",
    "  ├── _bronze_load_ts=20251101T060000/  -- 1000 rows (initial)\n",
    "  ├── _bronze_load_ts=20251108T060000/  -- 50 rows (delta)\n",
    "  └── _bronze_load_ts=20251115T060000/  -- 100 rows (delta)\n",
    "```\n",
    "\n",
    "Silver CDC merge:\n",
    "1. **Reconstruct current Bronze state** (latest row per business key)\n",
    "2. **Calculate row hash** for change detection\n",
    "3. **Compare with Silver**:\n",
    "   - Keys in Bronze but not Silver → **INSERT**\n",
    "   - Keys in both with different hash → **UPDATE**\n",
    "   - Keys in Silver but not Bronze → **DELETE** (marked as deleted)\n",
    "   - Keys in both with same hash → **UNCHANGED**\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Full CDC: INSERT, UPDATE, DELETE, UNCHANGED\n",
    "- Soft deletes (is_deleted flag, not physical deletion)\n",
    "- Row hash calculation using hash_utils\n",
    "- Delta MERGE operations (atomic)\n",
    "- Returns comprehensive metrics for logging\n",
    "\n",
    "## Load Modes\n",
    "\n",
    "- **snapshot/window**: Simple overwrite (no CDC needed)\n",
    "- **incremental**: Full CDC with delete detection\n",
    "\n",
    "This notebook is imported via `%run` from the master orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (set by orchestrator)\n",
    "RUN_ID = None  # Will be set by orchestrator\n",
    "DEBUG = False  # Enable debug output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## [1] Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module fabric.bootstrap\n",
    "# ---------------------\n",
    "# This cell enables a flexible module loading strategy:\n",
    "#\n",
    "# PRODUCTION (default): The `Files/code` directory is empty. This function does nothing,\n",
    "# and Python imports all modules from the stable, versioned Wheel in the Environment.\n",
    "#\n",
    "# DEVELOPMENT / HOTFIX: To bypass the 15-20 minute Fabric publish cycle for urgent fixes,\n",
    "# upload individual .py files to `Files/code` in the Lakehouse. This function prepends\n",
    "# that path to sys.path, so Python finds the override files first. All other modules\n",
    "# continue to load from the Wheel - only the uploaded files are replaced.\n",
    "#\n",
    "# Usage: Keep `Files/code` empty for production stability. Use it only for rapid\n",
    "# iteration during development or emergency hotfixes.\n",
    "\n",
    "from modules.fabric_bootstrap import ensure_module_path\n",
    "ensure_module_path()  # Now Python can find the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, current_timestamp, row_number, coalesce\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Optional\n",
    "from uuid import uuid4\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Import hash utilities\n",
    "import sys\n",
    "sys.path.append('/home/sparkadmin/source/repos/dwh_spark_processing/modules')  # Adjust if needed\n",
    "\n",
    "try:\n",
    "    from hash_utils import add_row_hash, compare_hash_differences\n",
    "    logger.info(\"✓ hash_utils imported successfully\")\n",
    "except ImportError as e:\n",
    "    logger.info(f\"⚠️  Warning: Could not import hash_utils: {e}\")\n",
    "    logger.info(\"   Make sure modules/hash_utils.py is in sys.path\")\n",
    "\n",
    "logger.info(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## [2] Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CDC utility functions from modules\n",
    "from modules.cdc_utils import (\n",
    "    reconstruct_bronze_current_state,\n",
    "    get_business_columns\n",
    ")\n",
    "\n",
    "logger.info(\"✓ CDC helper functions imported from modules.cdc_utils\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## [3] Core Silver CDC Merge Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Silver CDC processor from module\n",
    "from modules.silver_processor import process_silver_cdc_merge\n",
    "\n",
    "# Silver CDC merge function handles:\n",
    "# - Bronze state reconstruction (for incremental tables)\n",
    "# - Row hash calculation for change detection\n",
    "# - MERGE operations (INSERT + UPDATE)\n",
    "# - DELETE detection (soft deletes with is_deleted flag)\n",
    "# - Silver metadata management (_silver_inserted_ts, _silver_updated_ts, _silver_deleted_ts)\n",
    "#\n",
    "# Usage in orchestrator:\n",
    "# result = process_silver_cdc_merge(\n",
    "#     spark=spark,\n",
    "#     table_def=table,\n",
    "#     source_name=source,\n",
    "#     run_id=RUN_ID,\n",
    "#     run_ts=run_ts,\n",
    "#     debug=True\n",
    "# )\n",
    "\n",
    "logger.info(\"✓ Silver CDC merge function imported from modules.silver_processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## [4] Function Ready\n",
    "\n",
    "The `process_silver_cdc_merge()` function is now available for use by the orchestrator.\n",
    "\n",
    "**Usage pattern:**\n",
    "\n",
    "```python\n",
    "# In orchestrator notebook:\n",
    "%run \"20_silver_cdc_merge\"\n",
    "\n",
    "# Set RUN_ID\n",
    "RUN_ID = f\"run_{run_ts}\"\n",
    "\n",
    "# Process tables that have been successfully loaded to Bronze\n",
    "silver_results = []\n",
    "for table in tables_with_business_keys:\n",
    "    result = process_silver_cdc_merge(\n",
    "        table_def=table,\n",
    "        source_name=source,\n",
    "        run_ts=run_ts,\n",
    "        debug=True\n",
    "    )\n",
    "    silver_results.append(result)\n",
    "\n",
    "# Log results in batch\n",
    "log_batch(silver_results, layer=\"silver\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\" * 80)\n",
    "logger.info(\"SILVER CDC MERGE WORKER READY\")\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"\\nFunction available: process_silver_cdc_merge(table_def, source_name, run_ts, ...)\")\n",
    "logger.info(\"\\nCDC Capabilities:\")\n",
    "logger.info(\"  ✓ INSERT detection (new keys)\")\n",
    "logger.info(\"  ✓ UPDATE detection (changed rows via hash)\")\n",
    "logger.info(\"  ✓ DELETE detection (missing keys from Bronze)\")\n",
    "logger.info(\"  ✓ UNCHANGED tracking (same hash)\")\n",
    "logger.info(\"\\n⚠️  Remember to:\")\n",
    "logger.info(\"  1. Set RUN_ID before calling function\")\n",
    "logger.info(\"  2. Ensure business_keys defined in table config\")\n",
    "logger.info(\"  3. Run Bronze load successfully first\")\n",
    "logger.info(\"\\n✓ Silver CDC merge notebook loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
