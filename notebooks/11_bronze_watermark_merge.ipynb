{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11 ‚Äî Bronze Watermark Merge\n",
        "\n",
        "Merges watermark values from incremental load runtime files back into the central watermarks configuration.\n",
        "\n",
        "## Process Flow\n",
        "\n",
        "1. **Data Extraction Pipeline** (out of scope):\n",
        "   - Reads `watermarks.json` to get last processed value\n",
        "   - Extracts incremental data (rows > watermark)\n",
        "   - Writes parquet files to `Files/{source}/{run_ts}/{table}/`\n",
        "   - Writes new watermark to `runtime/{source}/{run_id}/{table}/watermark.parquet`\n",
        "\n",
        "2. **This Notebook**:\n",
        "   - Reads watermark parquet files from runtime folder\n",
        "   - Extracts max watermark per table\n",
        "   - Updates `watermarks.json` with new values\n",
        "   - Uses atomic write (tmp file + replace)\n",
        "\n",
        "3. **Next Run**:\n",
        "   - Extraction pipeline reads updated watermarks\n",
        "   - Continues from new watermark value\n",
        "\n",
        "## Important Notes\n",
        "\n",
        "- **This is the ONLY notebook that modifies watermarks.json**\n",
        "- Only runs for sources with incremental tables (e.g., vizier)\n",
        "- Uses PyArrow for reading (OneLake compatibility)\n",
        "- Atomic file updates prevent corruption\n",
        "- Runtime watermark files are NOT deleted (kept for audit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": ["parameters"]
      },
      "outputs": [],
      "source": [
        "# Parameters (Papermill compatible)\n",
        "wm_configpath = \"config/watermarks.json\"  # Relative path to watermarks config\n",
        "run_id = None                             # Run identifier (e.g., \"20251105T120000123\")\n",
        "source = None                             # Source system name (e.g., \"vizier\")\n",
        "wm_folder = None                          # Runtime watermark folder (e.g., \"runtime/vizier/{run_id}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [1] Imports and Path Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import Dict, Any, Optional\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow.dataset as ds\n",
        "\n",
        "print(\"‚úì Imports loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Auto-detect base path (Fabric vs Local)\n",
        "def detect_base_path() -> str:\n",
        "    \"\"\"\n",
        "    Auto-detect base path for Files directory.\n",
        "    \n",
        "    Returns:\n",
        "        '/lakehouse/default/Files' (Fabric) or 'Files' (Local)\n",
        "    \"\"\"\n",
        "    fabric_path = '/lakehouse/default/Files'\n",
        "    \n",
        "    if os.path.exists('/lakehouse/default'):\n",
        "        return fabric_path\n",
        "    else:\n",
        "        return 'Files'\n",
        "\n",
        "BASE_PATH = detect_base_path()\n",
        "\n",
        "print(f\"‚úì Base path: {BASE_PATH}\")\n",
        "print(f\"‚úì Environment: {'Fabric' if '/lakehouse' in BASE_PATH else 'Local'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate parameters\n",
        "if not source or not run_id:\n",
        "    raise ValueError(\"Parameters 'source' and 'run_id' are required\")\n",
        "\n",
        "# Build full paths\n",
        "wm_configpath_full = f'{BASE_PATH}/{wm_configpath}'\n",
        "\n",
        "# If wm_folder not provided, build default\n",
        "if wm_folder is None:\n",
        "    wm_folder = f\"runtime/{source}/{run_id}/\"\n",
        "\n",
        "wm_folder_full = f'{BASE_PATH}/{wm_folder}'\n",
        "\n",
        "print(f\"\\nParameters:\")\n",
        "print(f\"  Source: {source}\")\n",
        "print(f\"  Run ID: {run_id}\")\n",
        "print(f\"  Watermark config: {wm_configpath_full}\")\n",
        "print(f\"  Runtime folder: {wm_folder_full}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [2] Load Watermarks Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load watermarks config\n",
        "if not os.path.exists(wm_configpath_full):\n",
        "    raise FileNotFoundError(f\"Watermarks config not found: {wm_configpath_full}\")\n",
        "\n",
        "with open(wm_configpath_full, 'r') as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "print(f\"‚úì Loaded watermarks config\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find source in config\n",
        "sources = cfg.get(\"source\", [])\n",
        "src = next((s for s in sources if s.get(\"name\") == source), None)\n",
        "\n",
        "if not src:\n",
        "    raise ValueError(f\"Source '{source}' not found in watermarks config\")\n",
        "\n",
        "tables_map = src.get(\"tables\", {})\n",
        "print(f\"‚úì Found source '{source}' with {len(tables_map)} table watermarks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [3] Read Watermark Updates with PyArrow\n",
        "\n",
        "Uses PyArrow to read watermark parquet files in parallel.\n",
        "This approach is 10-100x faster than sequential file reading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if runtime folder exists\n",
        "if not os.path.exists(wm_folder_full):\n",
        "    print(f\"‚ö†Ô∏è  No watermark runtime folder found: {wm_folder_full}\")\n",
        "    print(f\"   This is normal if no incremental tables were processed\")\n",
        "    updates = {}\n",
        "else:\n",
        "    print(f\"\\nüìÇ Reading watermark updates from: {wm_folder_full}\")\n",
        "    updates = {}\n",
        "    \n",
        "    # List table folders\n",
        "    table_folders = [d for d in os.listdir(wm_folder_full) \n",
        "                     if os.path.isdir(os.path.join(wm_folder_full, d))]\n",
        "    \n",
        "    print(f\"   Found {len(table_folders)} table folders\")\n",
        "    \n",
        "    # Process each table folder\n",
        "    for table_name in table_folders:\n",
        "        table_path = os.path.join(wm_folder_full, table_name)\n",
        "        \n",
        "        try:\n",
        "            # List parquet files in this folder\n",
        "            parquet_files = [f for f in os.listdir(table_path) if f.endswith('.parquet')]\n",
        "            \n",
        "            if not parquet_files:\n",
        "                print(f\"   ‚ö†Ô∏è  {table_name}: No parquet files found\")\n",
        "                continue\n",
        "            \n",
        "            # Read all parquets with PyArrow\n",
        "            dataset = ds.dataset(table_path, format='parquet')\n",
        "            table = dataset.to_table()\n",
        "            \n",
        "            # Get max watermark if data exists\n",
        "            if table.num_rows > 0 and 'watermark' in table.column_names:\n",
        "                wm_column = table.column('watermark')\n",
        "                \n",
        "                # Find max non-null watermark\n",
        "                valid_watermarks = [\n",
        "                    wm.as_py() for wm in wm_column \n",
        "                    if wm.as_py() is not None and wm.as_py() != ''\n",
        "                ]\n",
        "                \n",
        "                if valid_watermarks:\n",
        "                    max_wm = max(valid_watermarks)\n",
        "                    updates[table_name] = max_wm\n",
        "                    print(f\"   ‚úì {table_name}: {max_wm}\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  {table_name}: No valid watermarks found\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è  {table_name}: No watermark column or empty table\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  {table_name}: Error reading watermark - {str(e)[:80]}\")\n",
        "    \n",
        "    print(f\"\\n‚úì Found {len(updates)} watermark updates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [4] Compare Old vs New Watermarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if updates:\n",
        "    print(\"\\nüîç Comparing old vs new watermarks:\")\n",
        "    print(f\"{'Table':<30} {'Old Watermark':<25} {'New Watermark':<25} {'Status':<15}\")\n",
        "    print(\"-\" * 95)\n",
        "    \n",
        "    for table, new_wm in sorted(updates.items()):\n",
        "        old_wm = tables_map.get(table)\n",
        "        \n",
        "        if old_wm == new_wm:\n",
        "            status = \"‚úì MATCH\"\n",
        "        elif old_wm is None:\n",
        "            status = \"üÜï NEW\"\n",
        "        else:\n",
        "            status = \"üîÑ UPDATE\"\n",
        "        \n",
        "        print(f\"{table:<30} {str(old_wm):<25} {str(new_wm):<25} {status:<15}\")\n",
        "else:\n",
        "    print(\"\\n‚ÑπÔ∏è  No watermark updates to process\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [5] Update Configuration\n",
        "\n",
        "Updates watermarks in the configuration dictionary where changes are detected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update watermarks\n",
        "changed = 0\n",
        "changes = []\n",
        "\n",
        "for table, new_wm in updates.items():\n",
        "    old_wm = tables_map.get(table)\n",
        "    \n",
        "    if old_wm != new_wm:\n",
        "        tables_map[table] = new_wm\n",
        "        changed += 1\n",
        "        changes.append({\n",
        "            \"table\": table,\n",
        "            \"old\": old_wm,\n",
        "            \"new\": new_wm\n",
        "        })\n",
        "        print(f\"  ‚úì Updated {table}: {old_wm} ‚Üí {new_wm}\")\n",
        "\n",
        "if changed > 0:\n",
        "    print(f\"\\n‚úì {changed} watermark(s) will be updated\")\n",
        "else:\n",
        "    print(\"\\n‚ÑπÔ∏è  No watermark changes detected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [6] Save Configuration (Atomic Write)\n",
        "\n",
        "Uses atomic file replacement to prevent corruption:\n",
        "1. Write to temporary file\n",
        "2. Replace original file with temp file\n",
        "3. OS guarantees atomic operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if changed > 0:\n",
        "    print(\"\\nüíæ Saving updated watermarks config...\")\n",
        "    \n",
        "    tmp_path = wm_configpath_full + \".tmp\"\n",
        "    \n",
        "    try:\n",
        "        # Write to temporary file\n",
        "        with open(tmp_path, 'w') as f:\n",
        "            json.dump(cfg, f, indent=2)\n",
        "        \n",
        "        print(f\"  ‚úì Wrote temporary file: {tmp_path}\")\n",
        "        \n",
        "        # Atomic replace\n",
        "        os.replace(tmp_path, wm_configpath_full)\n",
        "        \n",
        "        print(f\"  ‚úì Replaced original file: {wm_configpath_full}\")\n",
        "        print(\"\\n‚úì Watermarks config saved successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚úó Failed to save config: {str(e)}\")\n",
        "        \n",
        "        # Cleanup temp file if it exists\n",
        "        if os.path.exists(tmp_path):\n",
        "            try:\n",
        "                os.remove(tmp_path)\n",
        "                print(f\"  ‚úì Cleaned up temporary file\")\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        raise\n",
        "else:\n",
        "    print(\"\\n‚ÑπÔ∏è  No changes to save\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [7] Return Result\n",
        "\n",
        "Outputs processing summary for pipeline orchestration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build result summary\n",
        "result = {\n",
        "    \"source\": source,\n",
        "    \"run_id\": run_id,\n",
        "    \"updates_processed\": len(updates),\n",
        "    \"watermarks_changed\": changed,\n",
        "    \"config_updated\": changed > 0,\n",
        "    \"changes\": changes\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"WATERMARK MERGE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Source: {result['source']}\")\n",
        "print(f\"Run ID: {result['run_id']}\")\n",
        "print(f\"Watermark files processed: {result['updates_processed']}\")\n",
        "print(f\"Watermarks changed: {result['watermarks_changed']}\")\n",
        "print(f\"Config file updated: {result['config_updated']}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Print result as JSON for pipeline parsing\n",
        "result_json = json.dumps(result)\n",
        "print(f\"\\nRESULT_JSON: {result_json}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [8] Exit for Notebook Orchestration\n",
        "\n",
        "If using mssparkutils.notebook.run(), this provides the exit value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exit with result (for mssparkutils orchestration)\n",
        "try:\n",
        "    mssparkutils.notebook.exit(result_json)\n",
        "except NameError:\n",
        "    # mssparkutils not available (local environment)\n",
        "    print(\"\\n‚ÑπÔ∏è  mssparkutils not available (local environment)\")\n",
        "    print(\"   Notebook completed successfully\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
