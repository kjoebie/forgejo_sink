{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 11 ‚Äî Bronze Watermark Merge\n",
    "\n",
    "Merges watermark values from incremental load runtime files back into the central watermarks configuration.\n",
    "\n",
    "## Process Flow\n",
    "\n",
    "1. **Data Extraction Pipeline** (out of scope):\n",
    "   - Reads `watermarks.json` to get last processed value\n",
    "   - Extracts incremental data (rows > watermark)\n",
    "   - Writes parquet files to `Files/{source}/{run_ts}/{table}/`\n",
    "   - Writes new watermark to `runtime/{source}/{run_id}/{table}/watermark.parquet`\n",
    "\n",
    "2. **This Notebook**:\n",
    "   - Reads watermark parquet files from runtime folder\n",
    "   - Extracts max watermark per table\n",
    "   - Updates `watermarks.json` with new values\n",
    "   - Uses atomic write (tmp file + replace)\n",
    "\n",
    "3. **Next Run**:\n",
    "   - Extraction pipeline reads updated watermarks\n",
    "   - Continues from new watermark value\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- **This is the ONLY notebook that modifies watermarks.json**\n",
    "- Only runs for sources with incremental tables (e.g., vizier)\n",
    "- Uses PyArrow for reading (OneLake compatibility)\n",
    "- Atomic file updates prevent corruption\n",
    "- Runtime watermark files are NOT deleted (kept for audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (Papermill compatible)\n",
    "wm_configpath = \"config/watermarks.json\"  # Relative path to watermarks config\n",
    "run_id = None                             # Run identifier (e.g., \"20251105T120000123\")\n",
    "source = None                             # Source system name (e.g., \"vizier\")\n",
    "wm_folder = None                          # Runtime watermark folder (e.g., \"runtime/vizier/{run_id}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## [1] Imports and Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, Any, Optional\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "logger.info(\"‚úì Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect base path (Fabric vs Local)\n",
    "from modules.path_utils import get_base_path\n",
    "\n",
    "BASE_PATH = get_base_path()\n",
    "\n",
    "logger.info(f\"‚úì Base path: {BASE_PATH}\")\n",
    "logger.info(f\"‚úì Environment: {'Fabric' if '/lakehouse' in BASE_PATH else 'Local/Relative'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate parameters\n",
    "if not source or not run_id:\n",
    "    raise ValueError(\"Parameters 'source' and 'run_id' are required\")\n",
    "\n",
    "# Build full paths\n",
    "wm_configpath_full = f'{BASE_PATH}/{wm_configpath}'\n",
    "\n",
    "# If wm_folder not provided, build default\n",
    "if wm_folder is None:\n",
    "    wm_folder = f\"runtime/{source}/{run_id}/\"\n",
    "\n",
    "wm_folder_full = f'{BASE_PATH}/{wm_folder}'\n",
    "\n",
    "logger.info(f\"\\nParameters:\")\n",
    "logger.info(f\"  Source: {source}\")\n",
    "logger.info(f\"  Run ID: {run_id}\")\n",
    "logger.info(f\"  Watermark config: {wm_configpath_full}\")\n",
    "logger.info(f\"  Runtime folder: {wm_folder_full}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## [2] Load Watermarks Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load watermarks config\n",
    "if not os.path.exists(wm_configpath_full):\n",
    "    raise FileNotFoundError(f\"Watermarks config not found: {wm_configpath_full}\")\n",
    "\n",
    "with open(wm_configpath_full, 'r') as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "logger.info(f\"‚úì Loaded watermarks config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find source in config\n",
    "sources = cfg.get(\"source\", [])\n",
    "src = next((s for s in sources if s.get(\"name\") == source), None)\n",
    "\n",
    "if not src:\n",
    "    raise ValueError(f\"Source '{source}' not found in watermarks config\")\n",
    "\n",
    "tables_map = src.get(\"tables\", {})\n",
    "logger.info(f\"‚úì Found source '{source}' with {len(tables_map)} table watermarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## [3] Read Watermark Updates with PyArrow\n",
    "\n",
    "Uses PyArrow to read watermark parquet files in parallel.\n",
    "This approach is 10-100x faster than sequential file reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if runtime folder exists\n",
    "if not os.path.exists(wm_folder_full):\n",
    "    logger.info(f\"‚ö†Ô∏è  No watermark runtime folder found: {wm_folder_full}\")\n",
    "    logger.info(f\"   This is normal if no incremental tables were processed\")\n",
    "    updates = {}\n",
    "else:\n",
    "    logger.info(f\"\\nüìÇ Reading watermark updates from: {wm_folder_full}\")\n",
    "    updates = {}\n",
    "    \n",
    "    # List table folders\n",
    "    table_folders = [d for d in os.listdir(wm_folder_full) \n",
    "                     if os.path.isdir(os.path.join(wm_folder_full, d))]\n",
    "    \n",
    "    logger.info(f\"   Found {len(table_folders)} table folders\")\n",
    "    \n",
    "    # Process each table folder\n",
    "    for table_name in table_folders:\n",
    "        table_path = os.path.join(wm_folder_full, table_name)\n",
    "        \n",
    "        try:\n",
    "            # List parquet files in this folder\n",
    "            parquet_files = [f for f in os.listdir(table_path) if f.endswith('.parquet')]\n",
    "            \n",
    "            if not parquet_files:\n",
    "                logger.info(f\"   ‚ö†Ô∏è  {table_name}: No parquet files found\")\n",
    "                continue\n",
    "            \n",
    "            # Read all parquets with PyArrow\n",
    "            dataset = ds.dataset(table_path, format='parquet')\n",
    "            table = dataset.to_table()\n",
    "            \n",
    "            # Get max watermark if data exists\n",
    "            if table.num_rows > 0 and 'watermark' in table.column_names:\n",
    "                wm_column = table.column('watermark')\n",
    "                \n",
    "                # Find max non-null watermark\n",
    "                valid_watermarks = [\n",
    "                    wm.as_py() for wm in wm_column \n",
    "                    if wm.as_py() is not None and wm.as_py() != ''\n",
    "                ]\n",
    "                \n",
    "                if valid_watermarks:\n",
    "                    max_wm = max(valid_watermarks)\n",
    "                    updates[table_name] = max_wm\n",
    "                    logger.info(f\"   ‚úì {table_name}: {max_wm}\")\n",
    "                else:\n",
    "                    logger.info(f\"   ‚ö†Ô∏è  {table_name}: No valid watermarks found\")\n",
    "            else:\n",
    "                logger.info(f\"   ‚ö†Ô∏è  {table_name}: No watermark column or empty table\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.info(f\"   ‚ö†Ô∏è  {table_name}: Error reading watermark - {str(e)[:80]}\")\n",
    "    \n",
    "    logger.info(f\"\\n‚úì Found {len(updates)} watermark updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## [4] Compare Old vs New Watermarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if updates:\n",
    "    logger.info(\"\\nüîç Comparing old vs new watermarks:\")\n",
    "    logger.info(f\"{'Table':<30} {'Old Watermark':<25} {'New Watermark':<25} {'Status':<15}\")\n",
    "    logger.info(\"-\" * 95)\n",
    "    \n",
    "    for table, new_wm in sorted(updates.items()):\n",
    "        old_wm = tables_map.get(table)\n",
    "        \n",
    "        if old_wm == new_wm:\n",
    "            status = \"‚úì MATCH\"\n",
    "        elif old_wm is None:\n",
    "            status = \"üÜï NEW\"\n",
    "        else:\n",
    "            status = \"üîÑ UPDATE\"\n",
    "        \n",
    "        logger.info(f\"{table:<30} {str(old_wm):<25} {str(new_wm):<25} {status:<15}\")\n",
    "else:\n",
    "    logger.info(\"\\n‚ÑπÔ∏è  No watermark updates to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## [5] Update Configuration\n",
    "\n",
    "Updates watermarks in the configuration dictionary where changes are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update watermarks\n",
    "changed = 0\n",
    "changes = []\n",
    "\n",
    "for table, new_wm in updates.items():\n",
    "    old_wm = tables_map.get(table)\n",
    "    \n",
    "    if old_wm != new_wm:\n",
    "        tables_map[table] = new_wm\n",
    "        changed += 1\n",
    "        changes.append({\n",
    "            \"table\": table,\n",
    "            \"old\": old_wm,\n",
    "            \"new\": new_wm\n",
    "        })\n",
    "        logger.info(f\"  ‚úì Updated {table}: {old_wm} ‚Üí {new_wm}\")\n",
    "\n",
    "if changed > 0:\n",
    "    logger.info(f\"\\n‚úì {changed} watermark(s) will be updated\")\n",
    "else:\n",
    "    logger.info(\"\\n‚ÑπÔ∏è  No watermark changes detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## [6] Save Configuration (Atomic Write)\n",
    "\n",
    "Uses atomic file replacement to prevent corruption:\n",
    "1. Write to temporary file\n",
    "2. Replace original file with temp file\n",
    "3. OS guarantees atomic operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if changed > 0:\n",
    "    logger.info(\"\\nüíæ Saving updated watermarks config...\")\n",
    "    \n",
    "    tmp_path = wm_configpath_full + \".tmp\"\n",
    "    \n",
    "    try:\n",
    "        # Write to temporary file\n",
    "        with open(tmp_path, 'w') as f:\n",
    "            json.dump(cfg, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"  ‚úì Wrote temporary file: {tmp_path}\")\n",
    "        \n",
    "        # Atomic replace\n",
    "        os.replace(tmp_path, wm_configpath_full)\n",
    "        \n",
    "        logger.info(f\"  ‚úì Replaced original file: {wm_configpath_full}\")\n",
    "        logger.info(\"\\n‚úì Watermarks config saved successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.info(f\"\\n‚úó Failed to save config: {str(e)}\")\n",
    "        \n",
    "        # Cleanup temp file if it exists\n",
    "        if os.path.exists(tmp_path):\n",
    "            try:\n",
    "                os.remove(tmp_path)\n",
    "                logger.info(f\"  ‚úì Cleaned up temporary file\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        raise\n",
    "else:\n",
    "    logger.info(\"\\n‚ÑπÔ∏è  No changes to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## [7] Return Result\n",
    "\n",
    "Outputs processing summary for pipeline orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build result summary\n",
    "result = {\n",
    "    \"source\": source,\n",
    "    \"run_id\": run_id,\n",
    "    \"updates_processed\": len(updates),\n",
    "    \"watermarks_changed\": changed,\n",
    "    \"config_updated\": changed > 0,\n",
    "    \"changes\": changes\n",
    "}\n",
    "\n",
    "logger.info(\"\\n\" + \"=\" * 80)\n",
    "logger.info(\"WATERMARK MERGE SUMMARY\")\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(f\"Source: {result['source']}\")\n",
    "logger.info(f\"Run ID: {result['run_id']}\")\n",
    "logger.info(f\"Watermark files processed: {result['updates_processed']}\")\n",
    "logger.info(f\"Watermarks changed: {result['watermarks_changed']}\")\n",
    "logger.info(f\"Config file updated: {result['config_updated']}\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "# Print result as JSON for pipeline parsing\n",
    "result_json = json.dumps(result)\n",
    "logger.info(f\"\\nRESULT_JSON: {result_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## [8] Exit for Notebook Orchestration\n",
    "\n",
    "If using mssparkutils.notebook.run(), this provides the exit value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit with result (for mssparkutils orchestration)\n",
    "try:\n",
    "    mssparkutils.notebook.exit(result_json)\n",
    "except NameError:\n",
    "    # mssparkutils not available (local environment)\n",
    "    logger.info(\"\\n‚ÑπÔ∏è  mssparkutils not available (local environment)\")\n",
    "    logger.info(\"   Notebook completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
