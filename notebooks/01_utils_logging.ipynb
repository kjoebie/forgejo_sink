{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "009c544f",
      "metadata": {},
      "source": [
        "# 01 — Logging Utilities for Bronze and Silver Processing\n",
        "\n",
        "This notebook defines the logging infrastructure for the data pipeline:\n",
        "\n",
        "## Bronze Logging\n",
        "- `logs.bronze_processing_log` - Per-table processing results\n",
        "- `logs.bronze_run_summary` - Aggregated run statistics\n",
        "\n",
        "## Silver Logging\n",
        "- `logs.silver_processing_log` - Per-table CDC merge results\n",
        "- `logs.silver_run_summary` - Aggregated CDC statistics\n",
        "\n",
        "## Key Features\n",
        "- Batch logging (one write per run, not per table)\n",
        "- Append-only (no MERGE, maximum concurrency)\n",
        "- Partitioned by `run_date` and `table_name`\n",
        "- Helper functions for log retrieval and analysis\n",
        "\n",
        "**Architecture:** Bronze uses append with run_ts history for full CDC capability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427baa36",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Parameters (Papermill compatible)\n",
        "# These can be overridden when running via notebook orchestration\n",
        "LOG_SCHEMA = \"logs\"  # Database for all log tables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b9e9cf",
      "metadata": {},
      "source": [
        "## [1] Setup: Imports and Schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151ebf43",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import (\n",
        "    StructType, StructField, StringType, LongType, IntegerType,\n",
        "    TimestampType, DateType, DoubleType\n",
        ")\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as F\n",
        "from datetime import date\n",
        "from typing import List, Dict, Any, Optional\n",
        "import sys, os\n",
        "from pyspark.sql import DataFrame \n",
        "from delta.tables import DeltaTable\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a8f106",
      "metadata": {},
      "source": [
        "## [2] Bronze Processing Log Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d004fa5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bronze processing log - tracks individual table loads\n",
        "BRONZE_LOG_TABLE = \"bronze_processing_log\"\n",
        "BRONZE_LOG_TABLE_FULLNAME = f\"{LOG_SCHEMA}.{BRONZE_LOG_TABLE}\"\n",
        "\n",
        "bronze_log_schema = StructType([\n",
        "    # Identifiers\n",
        "    StructField(\"log_id\",           StringType(),    False),  # Unique log entry ID\n",
        "    StructField(\"run_id\",           StringType(),    False),  # Run identifier\n",
        "    StructField(\"run_date\",         DateType(),      False),  # Partition key (derived from run_ts)\n",
        "    StructField(\"run_ts\",           StringType(),    False),  # Run timestamp (yyyyMMddTHHmmssSSS)\n",
        "    \n",
        "    # Source information\n",
        "    StructField(\"source\",           StringType(),    False),  # Source system name\n",
        "    StructField(\"table_name\",       StringType(),    False),  # Table name (partition key)\n",
        "    StructField(\"load_mode\",        StringType(),    True),   # snapshot, incremental, window\n",
        "    \n",
        "    # Processing results\n",
        "    StructField(\"status\",           StringType(),    False),  # SUCCESS, FAILED, SKIPPED, EMPTY\n",
        "    StructField(\"rows_read\",        LongType(),      True),   # Rows read from parquet\n",
        "    StructField(\"rows_written\",     LongType(),      True),   # Rows written to Bronze\n",
        "    \n",
        "    # Timing\n",
        "    StructField(\"start_time\",       TimestampType(), True),\n",
        "    StructField(\"end_time\",         TimestampType(), True),\n",
        "    StructField(\"duration_seconds\", LongType(),      True),\n",
        "    \n",
        "    # Error handling\n",
        "    StructField(\"error_message\",    StringType(),    True),   # Truncated to 1000 chars\n",
        "    \n",
        "    # Source/target paths\n",
        "    StructField(\"parquet_path\",     StringType(),    True),   # Source parquet folder\n",
        "    StructField(\"delta_table\",      StringType(),    True),   # Target Bronze table\n",
        "])\n",
        "\n",
        "print(f\"Bronze log schema defined: {BRONZE_LOG_TABLE_FULLNAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d4b3a5",
      "metadata": {},
      "source": [
        "## [3] Bronze Run Summary Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78560347",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bronze run summary - aggregated statistics per run\n",
        "BRONZE_SUMMARY_TABLE = \"bronze_run_summary\"\n",
        "BRONZE_SUMMARY_TABLE_FULLNAME = f\"{LOG_SCHEMA}.{BRONZE_SUMMARY_TABLE}\"\n",
        "\n",
        "bronze_summary_schema = StructType([\n",
        "    # Run identifiers\n",
        "    StructField(\"run_id\",              StringType(),    False),\n",
        "    StructField(\"source\",              StringType(),    False),\n",
        "    StructField(\"run_ts\",              StringType(),    False),\n",
        "    StructField(\"run_date\",            DateType(),      False),\n",
        "    \n",
        "    # Timing\n",
        "    StructField(\"run_start\",           TimestampType(), False),\n",
        "    StructField(\"run_end\",             TimestampType(), True),\n",
        "    StructField(\"duration_seconds\",    LongType(),      True),\n",
        "    \n",
        "    # Table counts\n",
        "    StructField(\"total_tables\",        LongType(),      False),\n",
        "    StructField(\"tables_success\",      LongType(),      True),\n",
        "    StructField(\"tables_empty\",        LongType(),      True),\n",
        "    StructField(\"tables_failed\",       LongType(),      True),\n",
        "    StructField(\"tables_skipped\",      LongType(),      True),\n",
        "    \n",
        "    # Row counts\n",
        "    StructField(\"total_rows\",          LongType(),      True),\n",
        "    \n",
        "    # Performance metrics\n",
        "    StructField(\"workers\",             IntegerType(),   True),  # Parallel workers used\n",
        "    StructField(\"sum_task_seconds\",    DoubleType(),    True),  # Sum of all table durations\n",
        "    StructField(\"theoretical_min_sec\", DoubleType(),    True),  # Sum / workers\n",
        "    StructField(\"actual_time_sec\",     DoubleType(),    True),  # Wall clock time\n",
        "    StructField(\"efficiency_pct\",      DoubleType(),    True),  # (theoretical / actual) * 100\n",
        "    \n",
        "    # Failed tables list\n",
        "    StructField(\"failed_tables\",       StringType(),    True),  # JSON array of failed table names\n",
        "])\n",
        "\n",
        "print(f\"Bronze summary schema defined: {BRONZE_SUMMARY_TABLE_FULLNAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e1457c",
      "metadata": {},
      "source": [
        "## [4] Silver Processing Log Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e007ec8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Silver processing log - tracks CDC merge operations\n",
        "SILVER_LOG_TABLE = \"silver_processing_log\"\n",
        "SILVER_LOG_TABLE_FULLNAME = f\"{LOG_SCHEMA}.{SILVER_LOG_TABLE}\"\n",
        "\n",
        "silver_log_schema = StructType([\n",
        "    # Identifiers\n",
        "    StructField(\"log_id\",           StringType(),    False),\n",
        "    StructField(\"run_id\",           StringType(),    False),\n",
        "    StructField(\"run_date\",         DateType(),      False),\n",
        "    StructField(\"run_ts\",           StringType(),    False),\n",
        "    \n",
        "    # Source information\n",
        "    StructField(\"source\",           StringType(),    False),\n",
        "    StructField(\"table_name\",       StringType(),    False),\n",
        "    StructField(\"load_mode\",        StringType(),    True),\n",
        "    \n",
        "    # Processing results\n",
        "    StructField(\"status\",           StringType(),    False),  # SUCCESS, FAILED, SKIPPED\n",
        "    \n",
        "    # CDC statistics\n",
        "    StructField(\"rows_inserted\",    LongType(),      True),   # New rows added to Silver\n",
        "    StructField(\"rows_updated\",     LongType(),      True),   # Existing rows updated\n",
        "    StructField(\"rows_deleted\",     LongType(),      True),   # Rows marked as deleted\n",
        "    StructField(\"rows_unchanged\",   LongType(),      True),   # Rows with no changes\n",
        "    StructField(\"total_silver_rows\",LongType(),      True),   # Total rows in Silver after merge\n",
        "    \n",
        "    # Bronze source info\n",
        "    StructField(\"bronze_rows\",      LongType(),      True),   # Rows processed from Bronze\n",
        "    StructField(\"bronze_table\",     StringType(),    True),   # Source Bronze table\n",
        "    \n",
        "    # Timing\n",
        "    StructField(\"start_time\",       TimestampType(), True),\n",
        "    StructField(\"end_time\",         TimestampType(), True),\n",
        "    StructField(\"duration_seconds\", LongType(),      True),\n",
        "    \n",
        "    # Error handling\n",
        "    StructField(\"error_message\",    StringType(),    True),\n",
        "    \n",
        "    # Target\n",
        "    StructField(\"silver_table\",     StringType(),    True),   # Target Silver table\n",
        "])\n",
        "\n",
        "print(f\"Silver log schema defined: {SILVER_LOG_TABLE_FULLNAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67270f27",
      "metadata": {},
      "source": [
        "## [5] Silver Run Summary Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf01980b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Silver run summary - aggregated CDC statistics per run\n",
        "SILVER_SUMMARY_TABLE = \"silver_run_summary\"\n",
        "SILVER_SUMMARY_TABLE_FULLNAME = f\"{LOG_SCHEMA}.{SILVER_SUMMARY_TABLE}\"\n",
        "\n",
        "silver_summary_schema = StructType([\n",
        "    # Run identifiers\n",
        "    StructField(\"run_id\",              StringType(),    False),\n",
        "    StructField(\"source\",              StringType(),    False),\n",
        "    StructField(\"run_ts\",              StringType(),    False),\n",
        "    StructField(\"run_date\",            DateType(),      False),\n",
        "    \n",
        "    # Timing\n",
        "    StructField(\"run_start\",           TimestampType(), False),\n",
        "    StructField(\"run_end\",             TimestampType(), True),\n",
        "    StructField(\"duration_seconds\",    LongType(),      True),\n",
        "    \n",
        "    # Table counts\n",
        "    StructField(\"total_tables\",        LongType(),      False),\n",
        "    StructField(\"tables_success\",      LongType(),      True),\n",
        "    StructField(\"tables_failed\",       LongType(),      True),\n",
        "    StructField(\"tables_skipped\",      LongType(),      True),\n",
        "    \n",
        "    # Aggregate CDC statistics\n",
        "    StructField(\"total_inserts\",       LongType(),      True),\n",
        "    StructField(\"total_updates\",       LongType(),      True),\n",
        "    StructField(\"total_deletes\",       LongType(),      True),\n",
        "    StructField(\"total_unchanged\",     LongType(),      True),\n",
        "    \n",
        "    # Failed tables\n",
        "    StructField(\"failed_tables\",       StringType(),    True),\n",
        "])\n",
        "\n",
        "print(f\"Silver summary schema defined: {SILVER_SUMMARY_TABLE_FULLNAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "580a8173",
      "metadata": {},
      "source": [
        "## [6] Create Log Tables (Idempotent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411518f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure logs schema exists\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {LOG_SCHEMA}\")\n",
        "print(f\"✓ Schema '{LOG_SCHEMA}' ready\")\n",
        "\n",
        "# Create Bronze processing log\n",
        "if not spark.catalog.tableExists(BRONZE_LOG_TABLE_FULLNAME):\n",
        "    spark.sql(f\"\"\"\n",
        "        CREATE TABLE {BRONZE_LOG_TABLE_FULLNAME} (\n",
        "            log_id STRING,\n",
        "            run_id STRING,\n",
        "            run_date DATE,\n",
        "            run_ts STRING,\n",
        "            source STRING,\n",
        "            table_name STRING,\n",
        "            load_mode STRING,\n",
        "            status STRING,\n",
        "            rows_read LONG,\n",
        "            rows_written LONG,\n",
        "            start_time TIMESTAMP,\n",
        "            end_time TIMESTAMP,\n",
        "            duration_seconds LONG,\n",
        "            error_message STRING,\n",
        "            parquet_path STRING,\n",
        "            delta_table STRING\n",
        "        )\n",
        "        USING DELTA\n",
        "        PARTITIONED BY (run_date, table_name)\n",
        "    \"\"\")\n",
        "    print(f\"✓ Created: {BRONZE_LOG_TABLE_FULLNAME}\")\n",
        "else:\n",
        "    print(f\"✓ Exists: {BRONZE_LOG_TABLE_FULLNAME}\")\n",
        "\n",
        "# Create Bronze run summary\n",
        "if not spark.catalog.tableExists(BRONZE_SUMMARY_TABLE_FULLNAME):\n",
        "    spark.sql(f\"\"\"\n",
        "        CREATE TABLE {BRONZE_SUMMARY_TABLE_FULLNAME} (\n",
        "            run_id STRING,\n",
        "            source STRING,\n",
        "            run_ts STRING,\n",
        "            run_date DATE,\n",
        "            run_start TIMESTAMP,\n",
        "            run_end TIMESTAMP,\n",
        "            duration_seconds LONG,\n",
        "            total_tables LONG,\n",
        "            tables_success LONG,\n",
        "            tables_empty LONG,\n",
        "            tables_failed LONG,\n",
        "            tables_skipped LONG,\n",
        "            total_rows LONG,\n",
        "            workers LONG,\n",
        "            sum_task_seconds LONG,\n",
        "            theoretical_min_sec LONG,\n",
        "            actual_time_sec LONG,\n",
        "            efficiency_pct DOUBLE,\n",
        "            failed_tables STRING\n",
        "        )\n",
        "        USING DELTA\n",
        "        PARTITIONED BY (run_date)\n",
        "    \"\"\")\n",
        "    print(f\"✓ Created: {BRONZE_SUMMARY_TABLE_FULLNAME}\")\n",
        "else:\n",
        "    print(f\"✓ Exists: {BRONZE_SUMMARY_TABLE_FULLNAME}\")\n",
        "\n",
        "# Create Silver processing log\n",
        "if not spark.catalog.tableExists(SILVER_LOG_TABLE_FULLNAME):\n",
        "    spark.sql(f\"\"\"\n",
        "        CREATE TABLE {SILVER_LOG_TABLE_FULLNAME} (\n",
        "            log_id STRING,\n",
        "            run_id STRING,\n",
        "            run_date DATE,\n",
        "            run_ts STRING,\n",
        "            source STRING,\n",
        "            table_name STRING,\n",
        "            load_mode STRING,\n",
        "            status STRING,\n",
        "            rows_inserted LONG,\n",
        "            rows_updated LONG,\n",
        "            rows_deleted LONG,\n",
        "            rows_unchanged LONG,\n",
        "            total_silver_rows LONG,\n",
        "            bronze_rows LONG,\n",
        "            bronze_table STRING,\n",
        "            start_time TIMESTAMP,\n",
        "            end_time TIMESTAMP,\n",
        "            duration_seconds LONG,\n",
        "            error_message STRING,\n",
        "            silver_table STRING\n",
        "        )\n",
        "        USING DELTA\n",
        "        PARTITIONED BY (run_date, table_name)\n",
        "    \"\"\")\n",
        "    print(f\"✓ Created: {SILVER_LOG_TABLE_FULLNAME}\")\n",
        "else:\n",
        "    print(f\"✓ Exists: {SILVER_LOG_TABLE_FULLNAME}\")\n",
        "\n",
        "# Create Silver run summary\n",
        "if not spark.catalog.tableExists(SILVER_SUMMARY_TABLE_FULLNAME):\n",
        "    spark.sql(f\"\"\"\n",
        "        CREATE TABLE {SILVER_SUMMARY_TABLE_FULLNAME} (\n",
        "            run_id STRING,\n",
        "            source STRING,\n",
        "            run_ts STRING,\n",
        "            run_date DATE,\n",
        "            run_start TIMESTAMP,\n",
        "            run_end TIMESTAMP,\n",
        "            duration_seconds LONG,\n",
        "            total_tables LONG,\n",
        "            tables_success LONG,\n",
        "            tables_failed LONG,\n",
        "            tables_skipped LONG,\n",
        "            total_inserts LONG,\n",
        "            total_updates LONG,\n",
        "            total_deletes LONG,\n",
        "            total_unchanged LONG,\n",
        "            failed_tables STRING\n",
        "        )\n",
        "        USING DELTA\n",
        "        PARTITIONED BY (run_date)\n",
        "    \"\"\")\n",
        "    print(f\"✓ Created: {SILVER_SUMMARY_TABLE_FULLNAME}\")\n",
        "else:\n",
        "    print(f\"✓ Exists: {SILVER_SUMMARY_TABLE_FULLNAME}\")\n",
        "\n",
        "\n",
        "print(\"\\n✓ All log tables ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a6c0985",
      "metadata": {},
      "source": [
        "## [7] Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7d0d6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_run_date(run_ts: str) -> date:\n",
        "    \"\"\"\n",
        "    Convert a run_ts like '20251005T142752505' into a Python date(2025, 10, 5).\n",
        "    \n",
        "    This avoids Spark date parsing issues with ANSI mode.\n",
        "    \"\"\"\n",
        "    if not run_ts or len(run_ts) < 8:\n",
        "        raise ValueError(f\"run_ts '{run_ts}' is not in expected yyyymmddThhmmss format\")\n",
        "    \n",
        "    y = int(run_ts[0:4])\n",
        "    m = int(run_ts[4:6])\n",
        "    d = int(run_ts[6:8])\n",
        "    return date(y, m, d)\n",
        "\n",
        "\n",
        "def truncate_error_message(error_msg: Optional[str], max_length: int = 1000) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Truncate error messages to prevent bloating log tables.\n",
        "    \"\"\"\n",
        "    if not error_msg:\n",
        "        return None\n",
        "    \n",
        "    if len(error_msg) <= max_length:\n",
        "        return error_msg\n",
        "    \n",
        "    return error_msg[:max_length] + \"... [TRUNCATED]\"\n",
        "\n",
        "\n",
        "print(\"✓ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c953fd",
      "metadata": {},
      "source": [
        "## [8] Bronze Logging Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0269a676",
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_bronze_batch(records: List[Dict[str, Any]]) -> None:\n",
        "    \"\"\"\n",
        "    Write many Bronze log records in a single batch append.\n",
        "    \n",
        "    Args:\n",
        "        records: List of dicts with Bronze processing results\n",
        "    \n",
        "    Each record should contain:\n",
        "        - log_id, run_id, run_ts, source, table_name, load_mode\n",
        "        - status, rows_read, rows_written\n",
        "        - start_time, end_time, duration_seconds\n",
        "        - error_message, parquet_path, delta_table\n",
        "    \"\"\"\n",
        "    if not records:\n",
        "        return\n",
        "    \n",
        "    rows = []\n",
        "    for r in records:\n",
        "        run_ts = r.get(\"run_ts\")\n",
        "        if not run_ts:\n",
        "            raise ValueError(\"Bronze log record is missing run_ts\")\n",
        "        \n",
        "        # Build run_date from run_ts\n",
        "        rd = r.get(\"run_date\")\n",
        "        if rd is None:\n",
        "            rd = build_run_date(run_ts)\n",
        "        \n",
        "        # Truncate error message\n",
        "        error_msg = truncate_error_message(r.get(\"error_message\"))\n",
        "        \n",
        "        rows.append(Row(\n",
        "            log_id           = r.get(\"log_id\"),\n",
        "            run_id           = r.get(\"run_id\"),\n",
        "            run_date         = rd,\n",
        "            run_ts           = run_ts,\n",
        "            source           = r.get(\"source\"),\n",
        "            table_name       = r.get(\"table_name\"),\n",
        "            load_mode        = r.get(\"load_mode\"),\n",
        "            status           = r.get(\"status\"),\n",
        "            rows_read        = r.get(\"rows_read\"),\n",
        "            rows_written     = r.get(\"rows_written\"),\n",
        "            start_time       = r.get(\"start_time\"),\n",
        "            end_time         = r.get(\"end_time\"),\n",
        "            duration_seconds = r.get(\"duration_seconds\"),\n",
        "            error_message    = error_msg,\n",
        "            parquet_path     = r.get(\"parquet_path\"),\n",
        "            delta_table      = r.get(\"delta_table\"),\n",
        "        ))\n",
        "    \n",
        "    df = spark.createDataFrame(rows, schema=bronze_log_schema)\n",
        "    \n",
        "    (df.write\n",
        "       .format(\"delta\")\n",
        "       .mode(\"append\")\n",
        "       .saveAsTable(BRONZE_LOG_TABLE_FULLNAME))\n",
        "    \n",
        "    print(f\"✓ Logged {len(records)} Bronze records to {BRONZE_LOG_TABLE_FULLNAME}\")\n",
        "\n",
        "\n",
        "def log_bronze_summary(summary: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Write Bronze run summary.\n",
        "    \n",
        "    Args:\n",
        "        summary: Dict with run-level statistics\n",
        "    \"\"\"\n",
        "    run_ts = summary.get(\"run_ts\")\n",
        "    if not run_ts:\n",
        "        raise ValueError(\"Summary missing run_ts\")\n",
        "    \n",
        "    run_date = summary.get(\"run_date\")\n",
        "    if run_date is None:\n",
        "        run_date = build_run_date(run_ts)\n",
        "    \n",
        "    # Convert failed_tables list to JSON string\n",
        "    import json\n",
        "    failed_tables = summary.get(\"failed_tables\", [])\n",
        "    failed_tables_json = json.dumps(failed_tables) if failed_tables else None\n",
        "    \n",
        "    row = Row(\n",
        "        run_id              = summary.get(\"run_id\"),\n",
        "        source              = summary.get(\"source\"),\n",
        "        run_ts              = run_ts,\n",
        "        run_date            = run_date,\n",
        "        run_start           = summary.get(\"run_start\"),\n",
        "        run_end             = summary.get(\"run_end\"),\n",
        "        duration_seconds    = summary.get(\"duration_seconds\"),\n",
        "        total_tables        = summary.get(\"total_tables\"),\n",
        "        tables_success      = summary.get(\"tables_success\"),\n",
        "        tables_empty        = summary.get(\"tables_empty\"),\n",
        "        tables_failed       = summary.get(\"tables_failed\"),\n",
        "        tables_skipped      = summary.get(\"tables_skipped\"),\n",
        "        total_rows          = summary.get(\"total_rows\"),\n",
        "        workers             = summary.get(\"workers\"),\n",
        "        sum_task_seconds    = summary.get(\"sum_task_seconds\"),\n",
        "        theoretical_min_sec = summary.get(\"theoretical_min_sec\"),\n",
        "        actual_time_sec     = summary.get(\"actual_time_sec\"),\n",
        "        efficiency_pct      = summary.get(\"efficiency_pct\"),\n",
        "        failed_tables       = failed_tables_json,\n",
        "    )\n",
        "    \n",
        "    df = spark.createDataFrame([row], schema=bronze_summary_schema)\n",
        "    \n",
        "    (df.write\n",
        "       .format(\"delta\")\n",
        "       .mode(\"append\")\n",
        "       .saveAsTable(BRONZE_SUMMARY_TABLE_FULLNAME))\n",
        "    \n",
        "    print(f\"✓ Logged Bronze summary to {BRONZE_SUMMARY_TABLE_FULLNAME}\")\n",
        "\n",
        "\n",
        "print(\"✓ Bronze logging functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53e526fa",
      "metadata": {},
      "source": [
        "## [9] Silver Logging Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c270b7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_silver_batch(records: List[Dict[str, Any]]) -> None:\n",
        "    \"\"\"\n",
        "    Write many Silver log records in a single batch append.\n",
        "    \n",
        "    Args:\n",
        "        records: List of dicts with Silver CDC merge results\n",
        "    \n",
        "    Each record should contain:\n",
        "        - log_id, run_id, run_ts, source, table_name, load_mode\n",
        "        - status, rows_inserted, rows_updated, rows_deleted, rows_unchanged\n",
        "        - total_silver_rows, bronze_rows, bronze_table\n",
        "        - start_time, end_time, duration_seconds\n",
        "        - error_message, silver_table\n",
        "    \"\"\"\n",
        "    if not records:\n",
        "        return\n",
        "    \n",
        "    rows = []\n",
        "    for r in records:\n",
        "        run_ts = r.get(\"run_ts\")\n",
        "        if not run_ts:\n",
        "            raise ValueError(\"Silver log record is missing run_ts\")\n",
        "        \n",
        "        rd = r.get(\"run_date\")\n",
        "        if rd is None:\n",
        "            rd = build_run_date(run_ts)\n",
        "        \n",
        "        error_msg = truncate_error_message(r.get(\"error_message\"))\n",
        "        \n",
        "        rows.append(Row(\n",
        "            log_id           = r.get(\"log_id\"),\n",
        "            run_id           = r.get(\"run_id\"),\n",
        "            run_date         = rd,\n",
        "            run_ts           = run_ts,\n",
        "            source           = r.get(\"source\"),\n",
        "            table_name       = r.get(\"table_name\"),\n",
        "            load_mode        = r.get(\"load_mode\"),\n",
        "            status           = r.get(\"status\"),\n",
        "            rows_inserted    = r.get(\"rows_inserted\"),\n",
        "            rows_updated     = r.get(\"rows_updated\"),\n",
        "            rows_deleted     = r.get(\"rows_deleted\"),\n",
        "            rows_unchanged   = r.get(\"rows_unchanged\"),\n",
        "            total_silver_rows= r.get(\"total_silver_rows\"),\n",
        "            bronze_rows      = r.get(\"bronze_rows\"),\n",
        "            bronze_table     = r.get(\"bronze_table\"),\n",
        "            start_time       = r.get(\"start_time\"),\n",
        "            end_time         = r.get(\"end_time\"),\n",
        "            duration_seconds = r.get(\"duration_seconds\"),\n",
        "            error_message    = error_msg,\n",
        "            silver_table     = r.get(\"silver_table\"),\n",
        "        ))\n",
        "    \n",
        "    df = spark.createDataFrame(rows, schema=silver_log_schema)\n",
        "    \n",
        "    (df.write\n",
        "       .format(\"delta\")\n",
        "       .mode(\"append\")\n",
        "       .saveAsTable(SILVER_LOG_TABLE_FULLNAME))\n",
        "    \n",
        "    print(f\"✓ Logged {len(records)} Silver records to {SILVER_LOG_TABLE_FULLNAME}\")\n",
        "\n",
        "\n",
        "def log_silver_summary(summary: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Write Silver run summary.\n",
        "    \n",
        "    Args:\n",
        "        summary: Dict with run-level CDC statistics\n",
        "    \"\"\"\n",
        "    run_ts = summary.get(\"run_ts\")\n",
        "    if not run_ts:\n",
        "        raise ValueError(\"Summary missing run_ts\")\n",
        "    \n",
        "    run_date = summary.get(\"run_date\")\n",
        "    if run_date is None:\n",
        "        run_date = build_run_date(run_ts)\n",
        "    \n",
        "    import json\n",
        "    failed_tables = summary.get(\"failed_tables\", [])\n",
        "    failed_tables_json = json.dumps(failed_tables) if failed_tables else None\n",
        "    \n",
        "    row = Row(\n",
        "        run_id              = summary.get(\"run_id\"),\n",
        "        source              = summary.get(\"source\"),\n",
        "        run_ts              = run_ts,\n",
        "        run_date            = run_date,\n",
        "        run_start           = summary.get(\"run_start\"),\n",
        "        run_end             = summary.get(\"run_end\"),\n",
        "        duration_seconds    = summary.get(\"duration_seconds\"),\n",
        "        total_tables        = summary.get(\"total_tables\"),\n",
        "        tables_success      = summary.get(\"tables_success\"),\n",
        "        tables_failed       = summary.get(\"tables_failed\"),\n",
        "        tables_skipped      = summary.get(\"tables_skipped\"),\n",
        "        total_inserts       = summary.get(\"total_inserts\"),\n",
        "        total_updates       = summary.get(\"total_updates\"),\n",
        "        total_deletes       = summary.get(\"total_deletes\"),\n",
        "        total_unchanged     = summary.get(\"total_unchanged\"),\n",
        "        failed_tables       = failed_tables_json,\n",
        "    )\n",
        "    \n",
        "    df = spark.createDataFrame([row], schema=silver_summary_schema)\n",
        "    \n",
        "    (df.write\n",
        "       .format(\"delta\")\n",
        "       .mode(\"append\")\n",
        "       .saveAsTable(SILVER_SUMMARY_TABLE_FULLNAME))\n",
        "    \n",
        "    print(f\"✓ Logged Silver summary to {SILVER_SUMMARY_TABLE_FULLNAME}\")\n",
        "\n",
        "\n",
        "print(\"✓ Silver logging functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a5d66a",
      "metadata": {},
      "source": [
        "## [10] Query Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df29559",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bronze_logs_for_run(run_ts: str) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Get all Bronze processing logs for a specific run_ts.\n",
        "    \"\"\"\n",
        "    return spark.table(BRONZE_LOG_TABLE_FULLNAME).where(F.col(\"run_ts\") == run_ts)\n",
        "\n",
        "\n",
        "def get_silver_logs_for_run(run_ts: str) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Get all Silver processing logs for a specific run_ts.\n",
        "    \"\"\"\n",
        "    return spark.table(SILVER_LOG_TABLE_FULLNAME).where(F.col(\"run_ts\") == run_ts)\n",
        "\n",
        "\n",
        "def get_failed_tables(run_ts: str, layer: str = \"bronze\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Get list of failed table names for a run_ts.\n",
        "    \n",
        "    Args:\n",
        "        run_ts: Run timestamp\n",
        "        layer: \"bronze\" or \"silver\"\n",
        "    \n",
        "    Returns:\n",
        "        List of table names with status='FAILED'\n",
        "    \"\"\"\n",
        "    table = BRONZE_LOG_TABLE_FULLNAME if layer == \"bronze\" else SILVER_LOG_TABLE_FULLNAME\n",
        "    \n",
        "    failed = spark.table(table) \\\n",
        "        .where(f\"run_ts = '{run_ts}' AND status = 'FAILED'\") \\\n",
        "        .select(\"table_name\") \\\n",
        "        .distinct() \\\n",
        "        .collect()\n",
        "    \n",
        "    return [row.table_name for row in failed]\n",
        "\n",
        "\n",
        "def get_successful_tables(run_ts: str, layer: str = \"bronze\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Get list of successful table names for a run_ts.\n",
        "    \n",
        "    Args:\n",
        "        run_ts: Run timestamp\n",
        "        layer: \"bronze\" or \"silver\"\n",
        "    \n",
        "    Returns:\n",
        "        List of table names with status='SUCCESS'\n",
        "    \"\"\"\n",
        "    table = BRONZE_LOG_TABLE_FULLNAME if layer == \"bronze\" else SILVER_LOG_TABLE_FULLNAME\n",
        "    \n",
        "    success = spark.table(table) \\\n",
        "        .where(f\"run_ts = '{run_ts}' AND status = 'SUCCESS'\") \\\n",
        "        .select(\"table_name\") \\\n",
        "        .distinct() \\\n",
        "        .collect()\n",
        "    \n",
        "    return [row.table_name for row in success]\n",
        "\n",
        "\n",
        "def is_table_processed(run_ts: str, table_name: str, layer: str = \"bronze\") -> bool:\n",
        "    \"\"\"\n",
        "    Check if a specific table was successfully processed for a run_ts.\n",
        "    \n",
        "    Returns:\n",
        "        True if table has status='SUCCESS' for this run_ts\n",
        "    \"\"\"\n",
        "    table = BRONZE_LOG_TABLE_FULLNAME if layer == \"bronze\" else SILVER_LOG_TABLE_FULLNAME\n",
        "    \n",
        "    count = spark.table(table) \\\n",
        "        .where(f\"run_ts = '{run_ts}' AND table_name = '{table_name}' AND status = 'SUCCESS'\") \\\n",
        "        .count()\n",
        "    \n",
        "    return count > 0\n",
        "\n",
        "\n",
        "def get_latest_run_summary(source: str, layer: str = \"bronze\") -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Get the most recent run summary for a source.\n",
        "    \n",
        "    Returns:\n",
        "        Dict with summary data, or None if no runs found\n",
        "    \"\"\"\n",
        "    table = BRONZE_SUMMARY_TABLE_FULLNAME if layer == \"bronze\" else SILVER_SUMMARY_TABLE_FULLNAME\n",
        "    \n",
        "    latest = spark.table(table) \\\n",
        "        .where(f\"source = '{source}'\") \\\n",
        "        .orderBy(F.col(\"run_ts\").desc()) \\\n",
        "        .limit(1) \\\n",
        "        .collect()\n",
        "    \n",
        "    if not latest:\n",
        "        return None\n",
        "    \n",
        "    return latest[0].asDict()\n",
        "\n",
        "\n",
        "print(\"✓ Query helper functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64960887",
      "metadata": {},
      "source": [
        "## [11] Verification\n",
        "\n",
        "Quick verification that all tables exist and are queryable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e0401e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"LOGGING INFRASTRUCTURE VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "tables_to_check = [\n",
        "    BRONZE_LOG_TABLE_FULLNAME,\n",
        "    BRONZE_SUMMARY_TABLE_FULLNAME,\n",
        "    SILVER_LOG_TABLE_FULLNAME,\n",
        "    SILVER_SUMMARY_TABLE_FULLNAME,\n",
        "]\n",
        "\n",
        "for table_name in tables_to_check:\n",
        "    if not spark.catalog.tableExists(table_name):\n",
        "        print(f\"✗ {table_name:<40} NOT FOUND\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        count = spark.table(table_name).count()\n",
        "        print(f\"✓ {table_name:<40} {count:>10,} rows\")\n",
        "    except Exception as e:\n",
        "        print(f\"! {table_name:<40} ERROR: {type(e).__name__}: {e}\")\n",
        "\n",
        "print(\"\\n✓ Logging infrastructure ready for Bronze and Silver processing\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
