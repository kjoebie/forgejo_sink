{"cells":[{"cell_type":"markdown","source":["# Master Orchestrator: Bronze → Silver (→ Gold)\n","\n","Orchestrates the complete bronze and silver layer processing for a single source and run_ts.\n","\n","Called by pipeline after parquet files are written."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"435bd8a7-e2d9-46ee-ad9d-95272aa3c6dc"},{"cell_type":"code","source":["# Parameters (passed from pipeline)\n","source = \"ods_reports\"  # Will be set by pipeline\n","run_ts = \"20250923T060123389\"  # Will be set by pipeline\n","dag_path = \"/lakehouse/default/Files/config/dag_ods_reports_week.json\"  # Will be set by pipeline\n","drop_existing_tables = False  # Optional: force recreate\n","retry_tables = None #['Fact_Polis']\n","\n","# Validate parameters when called from pipeline\n","if not source or not run_ts or not dag_path:\n","    raise ValueError(\"Missing required parameters: source, run_ts, and dag_path must be provided\")\n","\n","print(f\"Master Orchestrator Starting...\")\n","print(f\"Source: {source}\")\n","print(f\"Run TS: {run_ts}\")\n","print(f\"DAG path: {dag_path}\")\n","print(f\"Retry tables: {retry_tables}\")\n","print(\"=\" * 80)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":23,"statement_ids":[23],"state":"finished","livy_statement_state":"available","session_id":"53c29526-6348-40e2-a89f-697e3d9be508","normalized_state":"finished","queued_time":"2025-10-31T11:27:18.8488532Z","session_start_time":null,"execution_start_time":"2025-10-31T11:27:18.8499891Z","execution_finish_time":"2025-10-31T11:27:19.4864338Z","parent_msg_id":"0bdc39a5-0257-4bb3-a400-63a0946f2d58"},"text/plain":"StatementMeta(, 53c29526-6348-40e2-a89f-697e3d9be508, 23, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Master Orchestrator Starting...\nSource: ods_reports\nRun TS: 20250923T060123389\nDAG path: /lakehouse/default/Files/config/dag_ods_reports_week.json\nRetry tables: None\n================================================================================\n"]}],"execution_count":21,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"193dee47-5693-48e0-a14c-781d9071c8d6"},{"cell_type":"markdown","source":["## Step 2b: Check for Incremental Tables\n","\n","Parse the DAG configuration to identify tables with incremental load mode. If incremental tables are present, execute the incremental processing logic within the current Spark session to avoid additional startup overhead.\n","\n","**Processing Logic:**\n","- Scans DAG for enabled tables with `load_mode: incremental`\n","- Executes incremental notebook if needed (session reuse)\n","- Skips if no incremental tables present\n","\n","This optimization ensures that incremental processing, bronze loading, and silver transformation all occur within a single Spark session, eliminating redundant 4-minute startup times."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1686f066-16bc-48be-9993-f2e12beccf0b"},{"cell_type":"code","source":["import json\n","\n","# Parse DAG to check for incremental tables\n","print(f\"Checking DAG for incremental tables...\")\n","\n","with open(dag_path, 'r') as f:\n","    dag_config = json.load(f)\n","\n","\n","# Filter incremental tables based on retry_tables parameter\n","if retry_tables and len(retry_tables) > 0:\n","    # Only check retry tables for incremental mode\n","    incremental_tables = [t for t in dag_config['tables'] \n","                         if t.get('load_mode') == 'incremental' \n","                         and t.get('enabled', True)\n","                         and t['name'] in retry_tables]\n","else:\n","    # Check all enabled tables\n","    incremental_tables = [t for t in dag_config['tables'] \n","                         if t.get('load_mode') == 'incremental' \n","                         and t.get('enabled', True)]\n","\n","if len(incremental_tables) > 0:\n","    print(f\"Found {len(incremental_tables)} incremental tables\")\n","    print(f\"Tables: {[t['name'] for t in incremental_tables[:5]]}\")\n","    print(\"Running incremental logic within this session...\")\n","    \n","    # Extract watermarks path from DAG\n","    wm_configpath = dag_config.get('watermarks_path', 'config/watermarks.json')\n","    \n","    # Build run_id from run_ts (format: run_20251005T142752505)\n","    run_id = f\"{run_ts}\"\n","    \n","    # Build watermark folder path\n","    wm_folder = f\"runtime/{source}/{run_id}/\"\n","    \n","    print(f\"Config: wm_configpath={wm_configpath}\")\n","    print(f\"Run ID: {run_id}\")\n","    print(f\"WM Folder: {wm_folder}\")\n","    \n","    try:\n","        result = mssparkutils.notebook.run(\n","            path=\"1.1 nb_inc_merge_watermarkfiles\",\n","            timeout_seconds=1800,\n","            arguments={\n","                \"wm_configpath\": wm_configpath,\n","                \"run_id\": run_id,\n","                \"source\": source,\n","                \"wm_folder\": wm_folder\n","            }\n","        )\n","        print(f\"  ✓ Incremental processing complete\")\n","    except Exception as e:\n","        print(f\"  ✗ Incremental processing FAILED: {str(e)}\")\n","        raise\n","else:\n","    print(f\"○ No incremental tables found - skipping incremental processing\")\n","\n","print(\"=\" * 80)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":24,"statement_ids":[24],"state":"finished","livy_statement_state":"available","session_id":"53c29526-6348-40e2-a89f-697e3d9be508","normalized_state":"finished","queued_time":"2025-10-31T11:27:18.9427699Z","session_start_time":null,"execution_start_time":"2025-10-31T11:27:19.4886936Z","execution_finish_time":"2025-10-31T11:27:20.7988148Z","parent_msg_id":"eb73e51e-af1c-4ebb-b715-7227000adc79"},"text/plain":"StatementMeta(, 53c29526-6348-40e2-a89f-697e3d9be508, 24, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Checking DAG for incremental tables...\n○ No incremental tables found - skipping incremental processing\n================================================================================\n"]}],"execution_count":22,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6456e2d2-670f-43a0-b185-f298d4dc08af"},{"cell_type":"code","source":["from datetime import datetime\n","\n","bronze_start = datetime.now()\n","print(f\"BRONZE: Loading parquet to Delta Tables...\")\n","\n","try:\n","    result = mssparkutils.notebook.run(\n","        \"1. nb_load_bronze\",\n","        timeout_seconds=3600,\n","        arguments={\n","            \"source\": source,\n","            \"run_ts\": run_ts,\n","            \"dag_path\": dag_path,\n","            \"drop_existing_tables\": str(drop_existing_tables).lower(),\n","            \"retry_tables\" : ','.join(retry_tables) if retry_tables and len(retry_tables) > 0 else \"None\"\n","        }\n","    )\n","    \n","    bronze_duration = (datetime.now() - bronze_start).total_seconds()\n","    print(f\"Bronze completed in {bronze_duration:.1f}s\")\n","    \n","except Exception as e:\n","    print(f\"Bronze FAILED: {str(e)}\")\n","    raise  # Stop pipeline"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":25,"statement_ids":[25],"state":"finished","livy_statement_state":"available","session_id":"53c29526-6348-40e2-a89f-697e3d9be508","normalized_state":"finished","queued_time":"2025-10-31T11:27:19.1111661Z","session_start_time":null,"execution_start_time":"2025-10-31T11:27:20.8007618Z","execution_finish_time":"2025-10-31T11:41:42.3866287Z","parent_msg_id":"01509a2f-1c6c-40c8-876f-783883283bcf"},"text/plain":"StatementMeta(, 53c29526-6348-40e2-a89f-697e3d9be508, 25, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["BRONZE: Loading parquet to Delta Tables...\n"]},{"output_type":"display_data","data":{"application/vnd.synapse.mssparkutilsrunmultiple-result+json":{"activities":[{"duration":858687,"start_time":1761910041870,"session_id":"53c29526-6348-40e2-a89f-697e3d9be508","created_time":1761910041870,"spark_pool":"Greehhouse_pool","in_pipeline":false,"snapshot_status":"success","notebook_name":"1. nb_load_bronze","exception":"","end_time":1761910900557,"snapshot_error":"","run_id":"5e444e71-bcdc-4ad3-ac66-28646acd1fdc","artifact_id":"99588c11-aac1-41c8-be72-d729f2fdf14e","progress":100,"status":"success","status_msg":"Success","activity_name":"0","args":{"source":"ods_reports","dag_path":"/lakehouse/default/Files/config/dag_ods_reports_week.json","drop_existing_tables":"false","retry_tables":"None","run_ts":"20250923T060123389"},"exit_value":"{\"success_count\": 33, \"failed_count\": 17, \"total_rows\": 8533345, \"duration_seconds\": 840.258398, \"failed_tables\": [\"CCS_SalesId\", \"DCM_Storno_CO\", \"Maatschappijlijst_Anva\", \"NKC_FACTUREN_permaand_export\", \"ProductOverzichtBrand\", \"OpenstaandeFacturenOuderdom\", \"PROEFPROLONGATIE\", \"Proefprolongatie_import\", \"PT_Dekking\", \"PT_FACTUREN_OpGroen\", \"Residencepolissen_met_buitenlandse_ass_belasting_Polis_Dekking\", \"SOS_FULL_AUTO\", \"SOS_FULL_AUTO_Modified\", \"SOS_FULL_Reis\", \"SOS_NKC_FULL_AUTO_NW\", \"SQ_POLIS_PECHHULP_AON_ANVA_COLLEC\", \"TBL_DATBES\"]}","root_artifact_id":"d0fa18d1-0251-47bf-865e-0b888356a6b9","capacity_id":"27BBC8F5-FF89-45ED-936E-322ECBABCD24","workspace_id":"f29eeacf-64cd-431a-913b-2ed71174251e"}],"numbers":{"pending":0,"running":0,"failed":0,"succeeded":1},"limit":50}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Bronze completed in 860.5s\n"]}],"execution_count":23,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8160ac9f-08e2-427a-8e7e-78f4d8c85c4e"},{"cell_type":"code","source":["silver_start = datetime.now()\n","print(f\"SILVER: Transforming to business layer...\")\n","\n","try:\n","    # TODO: Build Silver_Transform notebook\n","    # result = mssparkutils.notebook.run(\"Silver_Transform\", ...)\n","    print(\"  (Silver notebook not built yet - skipping)\")\n","    \n","    silver_duration = (datetime.now() - silver_start).total_seconds()\n","    print(f\"Silver completed in {silver_duration:.1f}s\")\n","    \n","except Exception as e:\n","    print(f\"Silver FAILED: {str(e)}\")\n","    raise"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":26,"statement_ids":[26],"state":"finished","livy_statement_state":"available","session_id":"53c29526-6348-40e2-a89f-697e3d9be508","normalized_state":"finished","queued_time":"2025-10-31T11:27:19.2229815Z","session_start_time":null,"execution_start_time":"2025-10-31T11:41:42.3886917Z","execution_finish_time":"2025-10-31T11:41:42.9787517Z","parent_msg_id":"818cbe0a-4122-4f49-9c9b-ee0b53769851"},"text/plain":"StatementMeta(, 53c29526-6348-40e2-a89f-697e3d9be508, 26, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["SILVER: Transforming to business layer...\n  (Silver notebook not built yet - skipping)\nSilver completed in 0.0s\n"]}],"execution_count":24,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a60472c-f9e5-460a-b8c2-7b7e0593e957"},{"cell_type":"code","source":["# # Test cell - direct testen\n","# test_table = \"Dim_Agent\"  # Klein tabel\n","# test_path = f\"/lakehouse/default/Files/greenhouse_sources/vizier/2025/10/05/20251005T144446117/Contactmomenten/Contactmomenten_I_00000.parquet\"\n","\n","# print(f\"Testing file:// protocol...\")\n","# print(f\"Path: {test_path}\")\n","\n","# try:\n","#     # Test 1: file:// protocol\n","#     df1 = spark.read.parquet(f\"file://{test_path}\")\n","#     print(f\"✓ file:// WORKS - {df1.count()} rows\")\n","# except Exception as e:\n","#     print(f\"✗ file:// FAILED: {str(e)[:150]}\")\n","    \n","#     # Test 2: PyArrow fallback\n","#     print(f\"\\nTrying PyArrow fallback...\")\n","#     import pyarrow.dataset as ds\n","#     arrow_table = ds.dataset(test_path, format='parquet').to_table()\n","#     print(f\"✓ PyArrow works - {arrow_table.num_rows} rows\")\n","\n","# df = spark.read.parquet(\"Files/greenhouse_sources/vizier/2025/10/05/20251005T144446117/Contactmomenten/Contactmomenten_I_00000.parquet\")\n","# # df now is a Spark DataFrame containing parquet data from \"Files/greenhouse_sources/vizier/2025/10/05/20251005T144446117/Contactmomenten/Contactmomenten_I_00000.parquet\".\n","# display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":27,"statement_ids":[27],"state":"finished","livy_statement_state":"available","session_id":"53c29526-6348-40e2-a89f-697e3d9be508","normalized_state":"finished","queued_time":"2025-10-31T11:27:19.2997733Z","session_start_time":null,"execution_start_time":"2025-10-31T11:41:42.9808805Z","execution_finish_time":"2025-10-31T11:41:43.6213387Z","parent_msg_id":"7ce03203-5d98-4eff-8de6-0705ec89570c"},"text/plain":"StatementMeta(, 53c29526-6348-40e2-a89f-697e3d9be508, 27, Finished, Available, Finished)"},"metadata":{}}],"execution_count":25,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"70cea105-a7fa-42de-a74e-36d64bf548f6"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"708925f5-6775-4eaa-abcb-d10995033b8c"}],"default_lakehouse":"708925f5-6775-4eaa-abcb-d10995033b8c","default_lakehouse_name":"lh_gh_bronze","default_lakehouse_workspace_id":"f29eeacf-64cd-431a-913b-2ed71174251e"}}},"nbformat":4,"nbformat_minor":5}